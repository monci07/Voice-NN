{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e3157a",
   "metadata": {},
   "source": [
    "# Activation word Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389345f0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook I will complete two different tasks:\n",
    "1. Create a large data set that combines positive and negative example words to train the neural network\n",
    "2. Design and test the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0c636",
   "metadata": {},
   "source": [
    "First, as in the previous notebook, I will add the necessary libraries to create the data set. The information and documentation of each API needed are:\n",
    "* For pyaudio: [main page](https://people.csail.mit.edu/hubert/pyaudio/) and [documentation](https://people.csail.mit.edu/hubert/pyaudio/docs/)\n",
    "* For NumPy: I used version [1.22.4](https://numpy.org/doc/1.22/)\n",
    "* For Random: [documentation](https://docs.python.org/3/library/random.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e60731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf2ef63",
   "metadata": {},
   "source": [
    "Next, I will load all the NumPy arrays of the previously recorded sessions into two lists (act, neg) to then turn them into NumPy arrays themselves. If all audios were recorded well the dimensions will be (number of examples x the size of the recording) and the notebook will not give me any error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74de8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "act, neg = [], []\n",
    "for i in range(15):\n",
    "    act.append(np.load(\"./Act_train/activation/\"+str(i+1)+\".npy\"))\n",
    "for i in range(120):\n",
    "    neg.append(np.load(\"./Act_train/negative/\"+str(i+1)+\".npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d2e5ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 44032)\n",
      "(120, 44032)\n"
     ]
    }
   ],
   "source": [
    "act, neg = np.array(act), np.array(neg)\n",
    "print(act.shape)\n",
    "print(neg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda42e42",
   "metadata": {},
   "source": [
    "Here, I declared two variables that will help by the time I start to work on the neural network, and the third one is for the function \"create_training_example\", number_of_act will help me get the number of activation examples so that with a counter I can go from the first to the last example without never going beyond it. That way I can include each example at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a07e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 688\n",
    "width = 64\n",
    "number_of_act=act.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dace4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_example(activates, negatives, num_active):\n",
    "    \"\"\"\n",
    "    Creates a simple training example at random from a activates, and negatives NumPy array.\n",
    "    \n",
    "    Arguments:\n",
    "    activates -- a list of NumPy array of the word you chose.\n",
    "    negatives -- a list of NumPy array of random words that are not the activation word.\n",
    "    num_activate -- The id of the next activation example.\n",
    "\n",
    "    Returns:\n",
    "    x -- the example that was chosen\n",
    "    y -- a 2d array that represents if the example is the activation word or not.\n",
    "    num_activate -- the updated id of the next activation example.\n",
    "    \"\"\"\n",
    "    #  yes/no\n",
    "    y = [0,0]\n",
    "    x = None\n",
    "    flag = np.random.randint(1, 100)\n",
    "    if flag%5==0:\n",
    "        x = activates[num_active]\n",
    "        y[0] = 1\n",
    "        num_active = (num_active+1)%number_of_act\n",
    "    else:\n",
    "        x = negatives[np.random.choice(len(negatives))]\n",
    "        y[1] = 1\n",
    "    \n",
    "    return x, y, num_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ca29e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x and y: <class 'numpy.ndarray'> <class 'list'>\n",
      "Size of x and y: (44032,) 2\n",
      "Values of variables: \n",
      " X: [-0.00866699 -0.0085144  -0.00814819 ...  0.0123291   0.01123047\n",
      "  0.01004028]\n",
      " Y: [0, 1]\n",
      " Id of activation: 0\n"
     ]
    }
   ],
   "source": [
    "x, y, num_active = create_training_example(act, neg, 0)\n",
    "print(\"Type of x and y:\",type(x), type(y))\n",
    "print(\"Size of x and y:\",x.shape, len(y))\n",
    "print(\"Values of variables: \")\n",
    "print(\" X:\", x)\n",
    "print(\" Y:\", y)\n",
    "print(\" Id of activation:\", num_active)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93cfaa1",
   "metadata": {},
   "source": [
    "Here comes the conclusion of the first task. Here I will do my training and development/test set. First things first, I need to make a decision on how big my training and development/test set should be. I decided that it will be two thousand examples, and the main reason for this number its because my computer doesn't have enough power to make more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c06b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a322d9",
   "metadata": {},
   "source": [
    "Next, it's the process of creating each set. Both procedures are practically the same and at the end of each, it will save the set in case you want to use it later. Also, I added a cell to see the shapes of both x and y and check if there's a positive example inside the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b781b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "z = 0\n",
    "for i in range(0, nsamples):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    x, y, z= create_training_example(act, neg, z)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y).reshape((nsamples, 2))\n",
    "    # Save the data for further uses\n",
    "np.save(f'./Act_train/XY_train/X_npy.npy', X)\n",
    "np.save(f'./Act_train/XY_train/Y_npy.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90eae90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and Y dimensions:  (2000, 44032) (2000, 2)\n",
      "Are there any positive examples in the training set?\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "print(\"X and Y dimensions: \",X.shape, Y.shape)\n",
    "print(\"Are there any positive examples in the training set?\")\n",
    "print(\"Yes\" if 1 in Y[:,0] else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb123aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = []\n",
    "Y_dev = []\n",
    "z = 0\n",
    "for i in range(0, nsamples):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    x, y, z= create_training_example(act, neg, z)\n",
    "    X_dev.append(x)\n",
    "    Y_dev.append(y)\n",
    "X_dev = np.array(X_dev)\n",
    "Y_dev = np.array(Y_dev).reshape((nsamples, 2))\n",
    "np.save(f'./Act_train/XY_dev/X_dev_npy.npy', X_dev)\n",
    "np.save(f'./Act_train/XY_dev/Y_dev_npy.npy', Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2486381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 44032)\n",
      "(2000, 2)\n",
      "Are there any positive examples in the training set?\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "print(X_dev.shape)\n",
    "print(Y_dev.shape)\n",
    "print(\"Are there any positive examples in the training set?\")\n",
    "print(\"Yes\" if 1 in Y_dev[:,0] else \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af4725",
   "metadata": {},
   "source": [
    "The next cell is to load previously made sets that you want to try to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0bb9aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"./Act_train/XY_train/X_npy.npy\")\n",
    "Y = np.load(\"./Act_train/XY_train/Y_npy.npy\")\n",
    "X_dev = np.load(\"./Act_train/XY_dev/X_dev_npy.npy\")\n",
    "Y_dev = np.load(\"./Act_train/XY_dev/Y_dev_npy.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de129e",
   "metadata": {},
   "source": [
    "Here starts the second task of this notebook. First of all, it needs to be pointed out that the base structure of this network was taken from one of the assignments of the  Deep Learning specialization offered by DeepLearning.AI on Coursera. Thank you so much to professor Andrew Ng and all the people that worked on that specialization.\n",
    "\n",
    "The reason of why, its that the base structure it's for a model that detects an activation word inside an audio file of 10 seconds, so I thought that based on that I could make a network to detect it in almost real-time with audios of 1 second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb24e6e",
   "metadata": {},
   "source": [
    "First I added all the tensor functions that I'll need. The information and documentation of the TensorFlow are:\n",
    "* [Documentation(tf.keras)](https://www.tensorflow.org/api_docs/python/tf/keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c422316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, BatchNormalization, Reshape, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c2d33",
   "metadata": {},
   "source": [
    "Next, it's my very first NN that I need to tune to make it work with what I needed. Here is my experience experimenting with it. (skip this part if you want, next cell I will make a little explanation on how it works out)\n",
    "At first, I tried to use .wav files that I needed to transform into spectrograms but the process was too long and it would have needed a decent amount of computation power to hear me, create a wave file, read that file, transform it into a spectrogram and feed it to the network.\n",
    "Based on that I decided to use the NumPy arrays because they were (in my point of view) data that didn't need a lot to be worked at. The process in real-time would just be to hear me, turn a byte array to float, and feed, I didn't need to write and read anything to my computer. An up till now, it has worked well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848598e",
   "metadata": {},
   "source": [
    "The model is this way:\n",
    "* The input layer: \n",
    " 1. A reshaping of the data so that will help the computer make calculations faster.\n",
    " 2. A Convolutional layer of 1 dimension.\n",
    " 3. A batch normalization so that we can eliminate negative numbers.\n",
    " 4. A activation using a \"relu\" function.\n",
    " 5. A Dropout of everything down of 85%.\n",
    "* The hidden layers: All hidden layers are composed of a GRU function, a Dropout, and a BatchNormalization\n",
    " * After some high-bias results I ended up making the network deeper and decreasing the number of units because I noticed that with every new hidden layer the accuracy started to go up and the loss go down. I assumed it was because the number of important characteristics was more evidently with every new layer.\n",
    "* The output layer: this layer was composed by a TimeDistributed function as was a important port for the based model and a Dense function acommponied by a Flatten of the result of the TimeDistributed.\n",
    " * The 2 inside the last function it refers to the two labels fo the data:\n",
    "   * \"Yes\", its the activation word.\n",
    "   * \"No\", its not the activation word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbfcf8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelf(input_shape):\n",
    "    \"\"\"\n",
    "    Creates a experimental model of a NN that detects a activation word based on a NumPy array\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    X = Reshape((width, length))(X_input)\n",
    "    X = Conv1D(filters = 196, kernel_size=5, strides=2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = Dropout(rate=0.85)(X)                                  \n",
    "\n",
    "    X = GRU(units = 128, return_sequences=True)(X)\n",
    "    X = Dropout(rate = 0.85)(X)\n",
    "    X = BatchNormalization()(X)                           \n",
    "    \n",
    "    X = GRU(units = 128, return_sequences=True)(X)\n",
    "    X = Dropout(rate = 0.85)(X)       \n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = GRU(units = 128, return_sequences=True)(X)\n",
    "    X = Dropout(rate = 0.85)(X)       \n",
    "    X = BatchNormalization()(X) \n",
    "    \n",
    "    X = GRU(units = 60, return_sequences=True)(X)\n",
    "    X = Dropout(rate = 0.85)(X)       \n",
    "    X = BatchNormalization()(X) \n",
    "    \n",
    "    X = GRU(units = 60, return_sequences=True)(X)\n",
    "    X = Dropout(rate = 0.85)(X)       \n",
    "    X = BatchNormalization()(X) \n",
    "    \n",
    "    X = GRU(units = 30, return_sequences=True)(X)\n",
    "    X = Dropout(rate = 0.90)(X)       \n",
    "    X = BatchNormalization()(X)  \n",
    "    \n",
    "    X = TimeDistributed(Dense(2, activation = \"sigmoid\"))(X)\n",
    "    X = (Dense(2, activation = \"sigmoid\"))(Flatten()(X))\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68144a1d",
   "metadata": {},
   "source": [
    "Here we call the function and pass the second part of the dimension of the data set, that will be the size of each example. if the compiling went well we should see the summary of the layers in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865fab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelf(input_shape = (X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9db27f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 44032)]           0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 688)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 30, 196)           674436    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 196)          784       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 30, 196)           0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 196)           0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 30, 128)           125184    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30, 128)           0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 30, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 30, 128)           99072     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30, 128)           0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 30, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 30, 128)           99072     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 30, 128)           0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 30, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 30, 60)            34200     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 30, 60)            0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 30, 60)           240       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 30, 60)            21960     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 30, 60)            0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 30, 60)           240       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 30, 30)            8280      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 30, 30)            0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 30, 30)           120       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 30, 2)            62        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 60)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,065,308\n",
      "Trainable params: 1,063,848\n",
      "Non-trainable params: 1,460\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20b4a77",
   "metadata": {},
   "source": [
    "And just before training, I added an Adam optimizer with a learning rate of 1e-3 because after experimenting with several values, this one was the best one for the model. I didn't touch the betas because they were already (as far as I understand it) what most people use.\n",
    "The loss function is a binary cross-entropy because it's what the base model use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8306d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f411e3",
   "metadata": {},
   "source": [
    "The moment of truth, I will finally train and tests the model. I found out that the best course of action for that the model get the best possible results is to run the model 30 times through the train set (30 epochs) in batches of 5. After doing that, the next cell will evaluate it with the dev/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32344ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "400/400 [==============================] - 21s 35ms/step - loss: 0.5306 - accuracy: 0.7790\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.5093 - accuracy: 0.8005\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.5039 - accuracy: 0.8005\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.4753 - accuracy: 0.8005\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.4389 - accuracy: 0.8000\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.3843 - accuracy: 0.8015\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.3607 - accuracy: 0.8155\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.3139 - accuracy: 0.8605\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 15s 36ms/step - loss: 0.2881 - accuracy: 0.8645\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.2460 - accuracy: 0.9055\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 14s 34ms/step - loss: 0.2281 - accuracy: 0.9120\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.2066 - accuracy: 0.9160\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.1686 - accuracy: 0.9370\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 14s 34ms/step - loss: 0.1202 - accuracy: 0.9610\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.1291 - accuracy: 0.9535\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.1241 - accuracy: 0.9575\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 14s 36ms/step - loss: 0.1073 - accuracy: 0.9685\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.0937 - accuracy: 0.9645\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 14s 36ms/step - loss: 0.0787 - accuracy: 0.9785\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.1070 - accuracy: 0.9615\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 14s 36ms/step - loss: 0.0778 - accuracy: 0.9730\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 14s 36ms/step - loss: 0.0843 - accuracy: 0.9710\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.0788 - accuracy: 0.9725\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.0689 - accuracy: 0.9765\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.0829 - accuracy: 0.9750\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.0820 - accuracy: 0.9735\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.0947 - accuracy: 0.9690\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 14s 34ms/step - loss: 0.0509 - accuracy: 0.9840\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 14s 35ms/step - loss: 0.0527 - accuracy: 0.9845\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 14s 34ms/step - loss: 0.0575 - accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x140bfd03490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size = 5, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf362d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 24ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Dev set accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "loss, acc, = model.evaluate(X_dev, Y_dev)\n",
    "print(\"Dev set accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b0eb3",
   "metadata": {},
   "source": [
    "This past is for saving and loading the model if you want to continue to test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/act_word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7bb8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model/act_word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17678ff",
   "metadata": {},
   "source": [
    "Here is where I tested out by hand how well it works. First by using an example of any of the sets then comparing it with the real value, and then by using a fresh example: recording a word either the activation or a negative one to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d0b58b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.655904e-04, 9.998277e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[1].reshape((1,X.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2df8800f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f2f5c",
   "metadata": {},
   "source": [
    "Here are the necessary cells to try how well will work with a fresh recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudiob\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paFloat32\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 1.01\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "inputs = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = bytearray()\n",
    "print(\"* recording\")\n",
    "for j in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    print(j)\n",
    "    frames += inputs.read(CHUNK)\n",
    "frames = np.frombuffer(frames, dtype = \"float32\")\n",
    "print(\"\\nPrediction\")\n",
    "model.predict(frames.reshape((1,frames.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0628195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
