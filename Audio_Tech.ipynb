{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fcef1e",
   "metadata": {},
   "source": [
    "# Audio tech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e5cd3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, I put to the test how well the API of pyaudio merges with the idea I have for my project and also to make the dataset I will need for my project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bda385",
   "metadata": {},
   "source": [
    "Leaving aside the imports needed for the recording and saving of the data, the first part of this notebook is only to get a fill of the API. The documentation and information for each API is:\n",
    "* For pyaudio: [main page](https://people.csail.mit.edu/hubert/pyaudio/) and [documentation](https://people.csail.mit.edu/hubert/pyaudio/docs/)\n",
    "* For NumPy: I used version [1.22.4](https://numpy.org/doc/1.22/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8119dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import wave\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caea901",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paFloat32\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 1\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "inputs = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "outputs = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                output=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "#stream.stop_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264aeb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "print(\"* recording\")\n",
    "aux = bytearray()\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = inputs.read(CHUNK)\n",
    "        aux += data\n",
    "        print(len(aux))\n",
    "        frames.append(data)\n",
    "print(\"* done recording\")\n",
    "for i in range(len(frames)):\n",
    "    outputs.write(frames[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedc214",
   "metadata": {},
   "source": [
    "## Generating data set for activation word training\n",
    "Starting here I recorded NumPys arrays of audios for the 'activation' and 'negative' parts of the data set. The way it works is that the cell it's gonna tell when it starts recording, and when it finishes doing so, it's gonna convert the array of audio bits into a NumPy array and then save it in a folder corresponding to the cell. (if it 'activation' in an activation sample folder, and if it's 'negative' in a negative sample folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8172e9c",
   "metadata": {},
   "source": [
    "The number of samples for each its not final and it may change on the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2300d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation using numpy arrays\n",
    "n_samples = 15\n",
    "for i in range(n_samples):\n",
    "    frames = bytearray()\n",
    "    print(\"* recording\")\n",
    "    for j in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        print(i)\n",
    "        frames += inputs.read(CHUNK)\n",
    "    frames = np.frombuffer(frames, dtype = \"float32\")\n",
    "    np.save(f'./Act_train/activation/' + str(i+1) + '.npy', frames)\n",
    "    clear_output(wait=True)\n",
    "    print(\"* done recording \"+ str(i+1) + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negatives using numpy arrays\n",
    "n_samples = 120\n",
    "for i in range(n_samples):\n",
    "    frames = bytearray()\n",
    "    print(\"* recording\")\n",
    "    for j in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        print(i)\n",
    "        frames += inputs.read(CHUNK)\n",
    "    frames = np.frombuffer(frames, dtype = \"float32\")\n",
    "    np.save(f'./Act_train/negative/' + str(i+1) + '.npy', frames)\n",
    "    clear_output(wait=True)\n",
    "    print(\"* done recording \"+ str(i+1) + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a49d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.close()\n",
    "outputs.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f727a4",
   "metadata": {},
   "source": [
    "And with this, the first part of the project is finished. I will omit the data set because it's audio arrays of my voice and I do not have enough experience to know if this will affect anyone that tries to use it. That's why I'm adding this notebook so that anyone can make their own data set and train the model using their voice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
